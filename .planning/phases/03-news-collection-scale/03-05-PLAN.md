---
phase: 03-news-collection-scale
plan: 05
type: execute
wave: 3
depends_on: ["03-01"]
files_modified:
  - app/services/relevance_scorer.py
  - app/config.py
autonomous: true

must_haves:
  truths:
    - "System uses AI relevance scoring to filter low-value content"
    - "Keyword filtering runs first (free) before AI scoring"
    - "AI scoring only used for marginal cases"
  artifacts:
    - path: "app/services/relevance_scorer.py"
      provides: "AI relevance pre-filter"
      exports: ["RelevanceScorer"]
      min_lines: 80
  key_links:
    - from: "app/services/relevance_scorer.py"
      to: "openai"
      via: "AzureOpenAI client"
      pattern: "from openai import AzureOpenAI"
    - from: "app/services/relevance_scorer.py"
      to: "app/services/sources/base.py"
      via: "ScrapedNewsItem import"
      pattern: "from app\\.services\\.sources import ScrapedNewsItem"
---

<objective>
Implement AI relevance scoring service for pre-filtering news items before expensive classification.

Purpose: Address NEWS-10 (AI relevance scoring filters low-value content). The two-pass approach (keyword matching first, AI for marginal cases) minimizes Azure OpenAI costs while ensuring high-quality filtering.

Output: RelevanceScorer service that filters ScrapedNewsItem lists using keyword matching and optional AI scoring.
</objective>

<execution_context>
@C:\Users\taylo\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\taylo\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/03-news-collection-scale/03-RESEARCH.md
@.planning/phases/03-news-collection-scale/03-01-SUMMARY.md

# Existing classifier pattern
@app/services/classifier.py
@app/services/sources/base.py
@app/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add relevance scoring configuration</name>
  <files>app/config.py</files>
  <action>
Add relevance scoring settings to Settings class:

```python
# Relevance Scoring
use_ai_relevance_scoring: bool = True  # Enable AI for marginal cases
relevance_keyword_threshold: int = 20  # Max items after keyword filter before using AI
relevance_ai_batch_size: int = 10  # Items to score per AI call
```

Place after the batch processing settings section.

These settings control:
- Whether to use AI scoring at all (can disable for cost control)
- Threshold for triggering AI (if keyword filtering leaves >20 items, use AI)
- Batch size for AI calls (to avoid token limits)
  </action>
  <verify>
```bash
python -c "
from app.config import get_settings
s = get_settings()
print(f'use_ai_relevance_scoring: {s.use_ai_relevance_scoring}')
print(f'relevance_keyword_threshold: {s.relevance_keyword_threshold}')
print(f'relevance_ai_batch_size: {s.relevance_ai_batch_size}')
"
```
Verify: use_ai_relevance_scoring=True, threshold=20, batch_size=10
  </verify>
  <done>
- use_ai_relevance_scoring configurable (default True)
- relevance_keyword_threshold configurable (default 20)
- relevance_ai_batch_size configurable (default 10)
  </done>
</task>

<task type="auto">
  <name>Task 2: Create relevance scorer service</name>
  <files>app/services/relevance_scorer.py</files>
  <action>
Create `app/services/relevance_scorer.py`:

```python
"""
AI relevance scoring service for pre-filtering news items.

Uses two-pass filtering:
1. Fast keyword matching (free)
2. AI scoring for marginal cases (paid)

This minimizes Azure OpenAI costs while maintaining quality filtering.
"""
import logging
from typing import Any

from openai import AzureOpenAI

from app.config import get_settings
from app.services.sources import ScrapedNewsItem

logger = logging.getLogger(__name__)


# Portuguese prompt for relevance scoring
RELEVANCE_PROMPT = """Você é um filtro de relevância para notícias de seguradoras brasileiras.

Avalie se cada notícia é RELEVANTE para monitoramento de risco da seguradora especificada.

Notícias IRRELEVANTES (marcar como N):
- Propaganda ou marketing genérico
- Notícias sobre outras empresas/setores não relacionadas
- Conteúdo duplicado ou muito similar
- Artigos muito antigos (mais de 7 dias)
- Eventos sociais sem impacto no negócio

Notícias RELEVANTES (marcar como S):
- Mudanças financeiras, resultados, balanços
- Ações regulatórias, ANS, SUSEP
- M&A, fusões, aquisições
- Mudanças de liderança executiva
- Processos judiciais, investigações
- Problemas operacionais, reclamações significativas
- Parcerias estratégicas importantes

Para cada notícia, responda apenas com S (relevante) ou N (irrelevante), separados por vírgula.
Exemplo: S,N,S,S,N"""


class RelevanceScorer:
    """
    Pre-filters news items by relevance before expensive classification.

    Two-pass approach:
    1. Keyword matching (fast, free) - filters obvious matches
    2. AI scoring (slow, paid) - only if too many items remain

    This reduces Azure OpenAI costs by ~70-80% compared to scoring all items.
    """

    def __init__(self):
        settings = get_settings()

        self.use_ai = settings.use_ai_relevance_scoring and settings.use_llm_summary
        self.keyword_threshold = settings.relevance_keyword_threshold
        self.ai_batch_size = settings.relevance_ai_batch_size

        if settings.is_azure_openai_configured() and self.use_ai:
            self.client = AzureOpenAI(
                azure_endpoint=settings.azure_openai_endpoint,
                api_key=settings.azure_openai_api_key,
                api_version=settings.azure_openai_api_version,
            )
            self.model = settings.azure_openai_deployment
        else:
            self.client = None
            self.model = None

    def score_batch(
        self,
        insurer_name: str,
        items: list[ScrapedNewsItem],
        max_results: int = 10,
    ) -> list[ScrapedNewsItem]:
        """
        Filter items by relevance to the insurer.

        Args:
            insurer_name: Name of the insurer being monitored
            items: Raw scraped news items
            max_results: Maximum items to return

        Returns:
            Filtered list of relevant items (up to max_results)
        """
        if not items:
            return []

        logger.debug(f"Scoring {len(items)} items for {insurer_name}")

        # Pass 1: Keyword filtering (fast, free)
        keyword_filtered = self._keyword_filter(insurer_name, items)
        logger.debug(f"After keyword filter: {len(keyword_filtered)} items")

        # If within threshold, no need for AI
        if len(keyword_filtered) <= max_results:
            return keyword_filtered

        # If above threshold but below AI threshold, truncate
        if not self.use_ai or not self.client:
            return keyword_filtered[:max_results]

        # Pass 2: AI scoring (slow, paid) - only for marginal cases
        if len(keyword_filtered) > self.keyword_threshold:
            logger.info(f"Using AI scoring for {len(keyword_filtered)} items (threshold: {self.keyword_threshold})")
            ai_filtered = self._ai_filter(insurer_name, keyword_filtered)
            return ai_filtered[:max_results]

        return keyword_filtered[:max_results]

    def _keyword_filter(
        self,
        insurer_name: str,
        items: list[ScrapedNewsItem],
    ) -> list[ScrapedNewsItem]:
        """
        Fast keyword-based relevance filtering.

        Keeps items that mention the insurer name or related terms.
        """
        # Extract keywords from insurer name
        name_parts = insurer_name.lower().split()
        # Keep parts with 3+ chars, ignore common words
        stopwords = {'de', 'do', 'da', 'dos', 'das', 'e', 'ou', 'a', 'o', 'em', 'para', 'com'}
        keywords = [p for p in name_parts if len(p) >= 3 and p not in stopwords]

        if not keywords:
            # If no good keywords, return all items
            return items

        filtered = []
        for item in items:
            text = f"{item.title} {item.description or ''}".lower()

            # Check if any keyword appears
            if any(kw in text for kw in keywords):
                filtered.append(item)

        return filtered

    def _ai_filter(
        self,
        insurer_name: str,
        items: list[ScrapedNewsItem],
    ) -> list[ScrapedNewsItem]:
        """
        AI-based relevance filtering using Azure OpenAI.

        Processes items in batches to respect token limits.
        """
        if not self.client or not items:
            return items

        relevant_items = []

        # Process in batches
        for i in range(0, len(items), self.ai_batch_size):
            batch = items[i:i + self.ai_batch_size]
            batch_results = self._score_batch_with_ai(insurer_name, batch)

            for item, is_relevant in zip(batch, batch_results):
                if is_relevant:
                    relevant_items.append(item)

        logger.info(f"AI filter: {len(relevant_items)}/{len(items)} items marked relevant")
        return relevant_items

    def _score_batch_with_ai(
        self,
        insurer_name: str,
        items: list[ScrapedNewsItem],
    ) -> list[bool]:
        """
        Score a batch of items using Azure OpenAI.

        Returns list of booleans indicating relevance.
        """
        if not items:
            return []

        # Format items for prompt
        items_text = "\n\n".join([
            f"{idx+1}. {item.title}\n   {(item.description or '')[:200]}"
            for idx, item in enumerate(items)
        ])

        user_prompt = f"""Seguradora: {insurer_name}

Avalie a relevância destas {len(items)} notícias:

{items_text}

Responda com S ou N para cada notícia, separados por vírgula:"""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": RELEVANCE_PROMPT},
                    {"role": "user", "content": user_prompt},
                ],
                temperature=0,
                max_tokens=100,  # Short response expected
            )

            # Parse response
            content = response.choices[0].message.content.strip()
            scores = [s.strip().upper() for s in content.split(",")]

            # Convert to booleans
            results = []
            for idx, item in enumerate(items):
                if idx < len(scores):
                    results.append(scores[idx] == "S")
                else:
                    # Default to relevant if response is incomplete
                    results.append(True)

            return results

        except Exception as e:
            logger.error(f"AI relevance scoring failed: {e}")
            # On error, mark all as relevant (fail open)
            return [True] * len(items)

    def health_check(self) -> dict[str, Any]:
        """Check relevance scorer status."""
        status = {
            "keyword_filter": "enabled",
            "ai_scoring": "enabled" if self.use_ai and self.client else "disabled",
            "keyword_threshold": self.keyword_threshold,
        }

        if self.client:
            try:
                # Quick ping to verify connectivity
                self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": "test"}],
                    max_tokens=1,
                )
                status["ai_status"] = "ok"
            except Exception as e:
                status["ai_status"] = f"error: {str(e)}"

        return status
```

Key design decisions:
- Two-pass filtering: keywords first (free), AI second (paid)
- Fail-open approach: on AI error, keep items rather than lose data
- Batch processing for AI to respect token limits
- Portuguese prompt for Brazilian news
- Configurable thresholds for cost control
  </action>
  <verify>
```bash
python -c "
from app.services.relevance_scorer import RelevanceScorer

scorer = RelevanceScorer()
print(f'use_ai: {scorer.use_ai}')
print(f'keyword_threshold: {scorer.keyword_threshold}')
print(f'ai_batch_size: {scorer.ai_batch_size}')

# Test keyword filter
from app.services.sources import ScrapedNewsItem
items = [
    ScrapedNewsItem(title='Bradesco Saude anuncia resultados', description='Lucro cresce 10%'),
    ScrapedNewsItem(title='Notícia sobre política', description='Senado aprova lei'),
]
filtered = scorer._keyword_filter('Bradesco Saude', items)
print(f'Keyword filter: {len(filtered)} of {len(items)} items')
"
```
Verify: Keyword filter keeps Bradesco item, removes politics item
  </verify>
  <done>
- RelevanceScorer class with score_batch() method
- Two-pass filtering: keyword matching then optional AI
- Configurable thresholds via settings
- Portuguese prompts for Brazilian context
- Fail-open error handling
- health_check() reports status
  </done>
</task>

<task type="auto">
  <name>Task 3: Add basic tests for relevance scorer</name>
  <files>tests/test_relevance_scorer.py</files>
  <action>
Create basic tests for RelevanceScorer:

```python
"""Tests for relevance scorer service."""
import pytest
from unittest.mock import Mock, patch

from app.services.relevance_scorer import RelevanceScorer
from app.services.sources import ScrapedNewsItem


class TestKeywordFilter:
    """Tests for keyword filtering."""

    def test_filters_by_name_parts(self):
        """Should keep items matching insurer name parts."""
        scorer = RelevanceScorer()
        items = [
            ScrapedNewsItem(title="Bradesco Saude anuncia resultados"),
            ScrapedNewsItem(title="Unimed cresce no mercado"),
            ScrapedNewsItem(title="Notícia sobre política geral"),
        ]

        filtered = scorer._keyword_filter("Bradesco Saude", items)

        # Should keep Bradesco item, remove others
        assert len(filtered) == 1
        assert "Bradesco" in filtered[0].title

    def test_handles_empty_list(self):
        """Should handle empty item list."""
        scorer = RelevanceScorer()
        filtered = scorer._keyword_filter("Test Insurer", [])
        assert filtered == []

    def test_handles_short_name(self):
        """Should handle short insurer names gracefully."""
        scorer = RelevanceScorer()
        items = [
            ScrapedNewsItem(title="ABC Insurance news"),
            ScrapedNewsItem(title="Other news"),
        ]

        # Short name "ABC" should still work
        filtered = scorer._keyword_filter("ABC", items)
        assert len(filtered) == 1

    def test_case_insensitive(self):
        """Keyword matching should be case insensitive."""
        scorer = RelevanceScorer()
        items = [
            ScrapedNewsItem(title="BRADESCO SAUDE em destaque"),
            ScrapedNewsItem(title="bradesco saude anuncia"),
        ]

        filtered = scorer._keyword_filter("Bradesco Saude", items)
        assert len(filtered) == 2


class TestScoreBatch:
    """Tests for score_batch method."""

    def test_returns_empty_for_empty_input(self):
        """Should return empty list for empty input."""
        scorer = RelevanceScorer()
        result = scorer.score_batch("Test", [])
        assert result == []

    def test_respects_max_results(self):
        """Should limit results to max_results."""
        scorer = RelevanceScorer()
        items = [
            ScrapedNewsItem(title=f"Test Insurer news {i}")
            for i in range(50)
        ]

        result = scorer.score_batch("Test Insurer", items, max_results=10)
        assert len(result) <= 10

    @patch.object(RelevanceScorer, '_ai_filter')
    def test_skips_ai_when_below_threshold(self, mock_ai):
        """Should not call AI when items below threshold."""
        scorer = RelevanceScorer()
        scorer.keyword_threshold = 20

        items = [
            ScrapedNewsItem(title=f"Test news {i}")
            for i in range(5)
        ]

        scorer.score_batch("Test", items, max_results=10)

        # AI should not be called for 5 items
        mock_ai.assert_not_called()


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
```
  </action>
  <verify>
```bash
python -m pytest tests/test_relevance_scorer.py -v 2>/dev/null || python -c "
# Fallback test
from app.services.relevance_scorer import RelevanceScorer
from app.services.sources import ScrapedNewsItem

scorer = RelevanceScorer()

# Test keyword filter
items = [
    ScrapedNewsItem(title='Bradesco Saude anuncia'),
    ScrapedNewsItem(title='Política nacional'),
]
filtered = scorer._keyword_filter('Bradesco Saude', items)
assert len(filtered) == 1, f'Expected 1, got {len(filtered)}'
print('Keyword filter test: PASS')

# Test empty input
assert scorer.score_batch('Test', []) == []
print('Empty input test: PASS')

# Test max_results
items = [ScrapedNewsItem(title=f'Test news {i}') for i in range(50)]
result = scorer.score_batch('Test', items, max_results=10)
assert len(result) <= 10, f'Expected <=10, got {len(result)}'
print('Max results test: PASS')

print('All relevance scorer tests passed')
"
```
  </verify>
  <done>
- Test file created at tests/test_relevance_scorer.py
- Tests cover keyword filtering, empty inputs, max_results
- Tests verify AI is skipped when below threshold
- Tests can run with pytest or standalone
  </done>
</task>

</tasks>

<verification>
Full verification:
```bash
# Module imports
python -c "
from app.services.relevance_scorer import RelevanceScorer
print('Import: OK')
"

# Configuration integration
python -c "
from app.config import get_settings
s = get_settings()
print(f'AI scoring config: use={s.use_ai_relevance_scoring}, threshold={s.relevance_keyword_threshold}')
"

# Keyword filtering
python -c "
from app.services.relevance_scorer import RelevanceScorer
from app.services.sources import ScrapedNewsItem

scorer = RelevanceScorer()
items = [
    ScrapedNewsItem(title='Bradesco Saude results'),
    ScrapedNewsItem(title='Political news'),
    ScrapedNewsItem(title='Bradesco investment'),
]
filtered = scorer._keyword_filter('Bradesco Saude', items)
print(f'Filtered {len(filtered)} of {len(items)} items')
"

# Health check
python -c "
from app.services.relevance_scorer import RelevanceScorer
scorer = RelevanceScorer()
status = scorer.health_check()
print(f'Health: {status}')
"
```
</verification>

<success_criteria>
1. Configuration extended with relevance scoring settings
2. RelevanceScorer uses two-pass filtering (keyword then AI)
3. Keyword filtering is fast and free (no API calls)
4. AI scoring only triggered when items exceed threshold
5. Portuguese prompts for Brazilian context
6. Fail-open error handling (keep items on error)
7. Basic tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/03-news-collection-scale/03-05-SUMMARY.md`
</output>
