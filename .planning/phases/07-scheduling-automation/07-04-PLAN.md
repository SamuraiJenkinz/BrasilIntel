---
phase: 07-scheduling-automation
plan: 04
type: execute
wave: 2
depends_on: ["07-01", "07-02", "07-03"]
files_modified:
  - app/routers/runs.py
  - tests/test_scheduler_integration.py
autonomous: false

must_haves:
  truths:
    - "Scheduled runs set trigger_type='scheduled' and scheduled_job_id"
    - "Run history shows scheduled vs manual distinction"
    - "Integration tests verify full scheduler workflow"
    - "Admin can view run history filtered by trigger_type"
  artifacts:
    - path: "app/routers/runs.py"
      provides: "Enhanced run tracking for scheduled jobs"
      contains: "trigger_type"
    - path: "tests/test_scheduler_integration.py"
      provides: "Integration tests for scheduler"
      min_lines: 50
  key_links:
    - from: "app/services/scheduler_service.py"
      to: "app/routers/runs.py"
      via: "HTTP call to execute endpoint"
      pattern: "/api/runs/execute/category"
---

<objective>
Integrate scheduled job tracking with run history and verify the complete scheduling system works end-to-end.

Purpose: This plan connects the scheduler to the run tracking system, ensuring scheduled runs are properly distinguished from manual runs in the history, and validates the complete workflow through integration tests.

Output: Enhanced run orchestration that tracks scheduled job metadata, and verified scheduling functionality.
</objective>

<execution_context>
@C:\Users\taylo\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\taylo\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/07-scheduling-automation/07-RESEARCH.md

# From prior plans
@app/services/scheduler_service.py
@app/schemas/schedule.py
@app/routers/schedules.py
@app/models/run.py
@app/schemas/run.py

# Existing run orchestration
@app/routers/runs.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add trigger_type filter to run listing</name>
  <files>app/routers/runs.py</files>
  <action>
Update the list_runs endpoint in app/routers/runs.py to support trigger_type filtering:

1. Add trigger_type parameter to list_runs:
```python
@router.get("", response_model=list[RunRead])
def list_runs(
    category: Optional[str] = None,
    status: Optional[str] = None,
    trigger_type: Optional[str] = None,  # Add this parameter
    limit: int = 20,
    db: Session = Depends(get_db),
) -> list[Run]:
    """
    List runs with optional filtering.

    Filters:
    - category: Health, Dental, or Group Life
    - status: pending, running, completed, failed
    - trigger_type: scheduled or manual
    """
    query = db.query(Run)

    if category:
        query = query.filter(Run.category == category)

    if status:
        query = query.filter(Run.status == status)

    if trigger_type:
        query = query.filter(Run.trigger_type == trigger_type)

    runs = query.order_by(Run.started_at.desc()).limit(limit).all()

    return runs
```

2. Add a dedicated endpoint to get latest run per category with schedule info:
```python
@router.get("/latest", response_model=dict)
def get_latest_runs(
    db: Session = Depends(get_db),
) -> dict:
    """
    Get the latest run for each category.

    Useful for dashboard display showing last run status per category.
    """
    from sqlalchemy import func

    categories = ["Health", "Dental", "Group Life"]
    latest = {}

    for category in categories:
        run = db.query(Run).filter(
            Run.category == category
        ).order_by(Run.started_at.desc()).first()

        if run:
            latest[category] = {
                "id": run.id,
                "status": run.status,
                "trigger_type": run.trigger_type,
                "started_at": run.started_at.isoformat() if run.started_at else None,
                "completed_at": run.completed_at.isoformat() if run.completed_at else None,
                "items_found": run.items_found,
                "email_status": run.email_status,
            }
        else:
            latest[category] = None

    return {"latest_runs": latest}
```

3. Add an endpoint to get run statistics:
```python
@router.get("/stats", response_model=dict)
def get_run_stats(
    days: int = 7,
    db: Session = Depends(get_db),
) -> dict:
    """
    Get run statistics for the past N days.

    Returns counts by status, trigger_type, and category.
    """
    from datetime import timedelta

    cutoff = datetime.utcnow() - timedelta(days=days)

    runs = db.query(Run).filter(Run.started_at >= cutoff).all()

    stats = {
        "period_days": days,
        "total_runs": len(runs),
        "by_status": {},
        "by_trigger_type": {},
        "by_category": {},
    }

    for run in runs:
        # Count by status
        stats["by_status"][run.status] = stats["by_status"].get(run.status, 0) + 1
        # Count by trigger_type
        stats["by_trigger_type"][run.trigger_type] = stats["by_trigger_type"].get(run.trigger_type, 0) + 1
        # Count by category
        stats["by_category"][run.category] = stats["by_category"].get(run.category, 0) + 1

    return stats
```
  </action>
  <verify>
```python
python -c "
from app.routers.runs import router
routes = [f'{r.methods} {r.path}' for r in router.routes if hasattr(r, 'methods')]
print('Run routes:')
for r in routes:
    print(f'  {r}')
"
```
Expected: Shows /latest and /stats routes in addition to existing routes.
  </verify>
  <done>Run listing supports trigger_type filter, plus new /latest and /stats endpoints for dashboard use.</done>
</task>

<task type="auto">
  <name>Task 2: Create integration tests for scheduler</name>
  <files>tests/test_scheduler_integration.py</files>
  <action>
Create comprehensive integration tests in tests/test_scheduler_integration.py:

```python
"""
Integration tests for the scheduling system.

Tests the complete scheduler workflow including:
- Scheduler startup/shutdown
- Job creation and management
- Schedule modification
- API endpoints
"""
import pytest
from datetime import datetime
from unittest.mock import patch, AsyncMock
from fastapi.testclient import TestClient

from app.main import app
from app.services.scheduler_service import SchedulerService


@pytest.fixture
def client():
    """FastAPI test client."""
    return TestClient(app)


@pytest.fixture
def scheduler():
    """Fresh scheduler instance (not started)."""
    # Reset singleton for clean test
    SchedulerService._instance = None
    SchedulerService._scheduler = None
    return SchedulerService()


class TestSchedulerService:
    """Tests for SchedulerService class."""

    def test_singleton_pattern(self, scheduler):
        """Verify scheduler is a singleton."""
        svc1 = SchedulerService()
        svc2 = SchedulerService()
        assert svc1 is svc2

    def test_job_id_generation(self, scheduler):
        """Verify job IDs follow pattern."""
        assert scheduler.get_job_id("Health") == "category_run_health"
        assert scheduler.get_job_id("Dental") == "category_run_dental"
        assert scheduler.get_job_id("Group Life") == "category_run_group_life"

    def test_timezone_is_sao_paulo(self, scheduler):
        """Verify São Paulo timezone configured."""
        assert str(scheduler.SAO_PAULO_TZ) == "America/Sao_Paulo"

    def test_scheduler_starts_and_stops(self, scheduler):
        """Verify scheduler lifecycle."""
        assert not scheduler._scheduler.running

        scheduler.start()
        assert scheduler._scheduler.running

        scheduler.shutdown(wait=False)
        assert not scheduler._scheduler.running

    def test_default_jobs_created_on_start(self, scheduler):
        """Verify 3 default jobs created on startup."""
        scheduler.start()

        jobs = scheduler._scheduler.get_jobs()
        job_ids = [j.id for j in jobs]

        assert "category_run_health" in job_ids
        assert "category_run_dental" in job_ids
        assert "category_run_group_life" in job_ids

        scheduler.shutdown(wait=False)

    def test_get_schedule_returns_info(self, scheduler):
        """Verify get_schedule returns correct structure."""
        scheduler.start()

        schedule = scheduler.get_schedule("Health")

        assert schedule is not None
        assert schedule["category"] == "Health"
        assert schedule["job_id"] == "category_run_health"
        assert "enabled" in schedule
        assert "next_run_time" in schedule
        assert "cron_expression" in schedule

        scheduler.shutdown(wait=False)

    def test_pause_and_resume_job(self, scheduler):
        """Verify pause/resume functionality."""
        scheduler.start()

        # Pause job
        result = scheduler.pause_job("Health")
        assert result["enabled"] == False

        # Resume job
        result = scheduler.resume_job("Health")
        assert result["enabled"] == True

        scheduler.shutdown(wait=False)

    def test_get_all_schedules(self, scheduler):
        """Verify get_all_schedules returns all 3 categories."""
        scheduler.start()

        schedules = scheduler.get_all_schedules()

        assert len(schedules) == 3
        categories = [s["category"] for s in schedules]
        assert "Health" in categories
        assert "Dental" in categories
        assert "Group Life" in categories

        scheduler.shutdown(wait=False)


class TestScheduleAPI:
    """Tests for schedule API endpoints."""

    def test_list_schedules(self, client):
        """Test GET /api/schedules returns all schedules."""
        response = client.get("/api/schedules")
        assert response.status_code == 200

        data = response.json()
        assert "schedules" in data
        assert "timezone" in data
        assert data["timezone"] == "America/Sao_Paulo"

    def test_get_schedule_by_category(self, client):
        """Test GET /api/schedules/{category}."""
        response = client.get("/api/schedules/Health")
        assert response.status_code == 200

        data = response.json()
        assert data["category"] == "Health"
        assert "job_id" in data
        assert "next_run_time" in data

    def test_get_schedule_invalid_category(self, client):
        """Test GET /api/schedules/{category} with invalid category."""
        response = client.get("/api/schedules/Invalid")
        assert response.status_code == 400

    def test_update_schedule_disable(self, client):
        """Test PUT /api/schedules/{category} to disable."""
        response = client.put(
            "/api/schedules/Health",
            json={"enabled": False}
        )
        assert response.status_code == 200

        data = response.json()
        assert data["enabled"] == False

        # Re-enable for other tests
        client.put("/api/schedules/Health", json={"enabled": True})

    def test_scheduler_health(self, client):
        """Test GET /api/schedules/health."""
        response = client.get("/api/schedules/health")
        assert response.status_code == 200

        data = response.json()
        assert "scheduler_running" in data
        assert "jobs_count" in data
        assert "timezone" in data

    def test_pause_and_resume_endpoints(self, client):
        """Test POST /api/schedules/{category}/pause and /resume."""
        # Pause
        response = client.post("/api/schedules/Dental/pause")
        assert response.status_code == 200
        assert response.json()["enabled"] == False

        # Resume
        response = client.post("/api/schedules/Dental/resume")
        assert response.status_code == 200
        assert response.json()["enabled"] == True


class TestRunFiltering:
    """Tests for run history filtering."""

    def test_list_runs_with_trigger_type(self, client):
        """Test GET /api/runs with trigger_type filter."""
        response = client.get("/api/runs?trigger_type=manual")
        assert response.status_code == 200

    def test_get_latest_runs(self, client):
        """Test GET /api/runs/latest."""
        response = client.get("/api/runs/latest")
        assert response.status_code == 200

        data = response.json()
        assert "latest_runs" in data

    def test_get_run_stats(self, client):
        """Test GET /api/runs/stats."""
        response = client.get("/api/runs/stats?days=7")
        assert response.status_code == 200

        data = response.json()
        assert "total_runs" in data
        assert "by_status" in data
        assert "by_trigger_type" in data
```

Run the tests to verify everything works.
  </action>
  <verify>
```bash
pytest tests/test_scheduler_integration.py -v --tb=short
```
Expected: All tests pass (may have warnings about scheduler already running, which is fine).
  </verify>
  <done>Integration tests created and passing for scheduler service and API endpoints.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Complete scheduling system with:
- APScheduler with São Paulo timezone
- 3 default jobs (Health 6 AM, Dental 7 AM, Group Life 8 AM)
- API endpoints at /api/schedules for management
- Run history filtering by trigger_type
- Scheduler health check integrated with /api/health
  </what-built>
  <how-to-verify>
1. Start the application:
   ```bash
   cd C:\BrasilIntel
   python -m uvicorn app.main:app --port 8000
   ```

2. Verify scheduler started (check logs for "Scheduler started successfully")

3. Test the endpoints in browser or curl:
   - http://localhost:8000/api/schedules - should show 3 schedules with next_run_time
   - http://localhost:8000/api/schedules/Health - should show Health schedule details
   - http://localhost:8000/api/schedules/health - should show scheduler_running: true
   - http://localhost:8000/api/health - should include scheduler status

4. Test schedule modification:
   ```bash
   # Disable Health schedule
   curl -X PUT http://localhost:8000/api/schedules/Health -H "Content-Type: application/json" -d '{"enabled": false}'

   # Verify disabled
   curl http://localhost:8000/api/schedules/Health
   # Should show enabled: false

   # Re-enable
   curl -X POST http://localhost:8000/api/schedules/Health/resume
   ```

5. Verify next_run_time shows São Paulo timezone (should be next 6/7/8 AM)

6. Check run history endpoints:
   - http://localhost:8000/api/runs/latest
   - http://localhost:8000/api/runs/stats?days=7
  </how-to-verify>
  <resume-signal>Type "approved" if all verifications pass, or describe any issues found.</resume-signal>
</task>

</tasks>

<verification>
After all tasks complete and checkpoint approved:
1. Scheduler starts automatically with app
2. 3 default jobs created for Health, Dental, Group Life
3. Jobs scheduled at correct São Paulo times (6, 7, 8 AM)
4. API endpoints work for viewing and modifying schedules
5. Run history can be filtered by trigger_type
6. Integration tests pass
</verification>

<success_criteria>
SCHD-01: System runs 3 scheduled jobs - VERIFIED by job creation on startup
SCHD-02: Default times 6/7/8 AM São Paulo - VERIFIED by next_run_time in API
SCHD-03: Admin can modify cron - VERIFIED by PUT /api/schedules/{category}
SCHD-04: Admin can enable/disable - VERIFIED by pause/resume endpoints
SCHD-05: Manual trigger via UI - VERIFIED by POST /api/schedules/{category}/trigger
SCHD-06: Run history tracking - VERIFIED by /api/runs with trigger_type filter
SCHD-07: Next run time displayed - VERIFIED by next_run_time in schedule info
</success_criteria>

<output>
After completion, create `.planning/phases/07-scheduling-automation/07-04-SUMMARY.md`
</output>
